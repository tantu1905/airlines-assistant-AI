<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            background-color: #1a171b;
            color: white;
            font-family: Arial, sans-serif;
            align-items: center;
            margin-left: 20px;
        }
        h1 {
            color: white;
        }
        ul {
            padding: 0;
            list-style-type: none;
        }
        input[type="text"] {
            width: 50%;
            padding: 10px;
            margin: 10px 0;
            border-radius: 5px;
            border: 1px solid lightgray;
        }
        button {
            padding: 10px;
            margin: 10px 0;
            border-radius: 5px;
            border: 1px solid lightgray;
            background-color: white;
            color: black;
            cursor: pointer;
        }
        img {
            width: 500px;
            height: 200px;
            margin-right: 10px;
            margin-left: 10px;
        }
        .openai-message {
            background: white;
            color: black;
            padding: 10px;
            margin-bottom: 5px;
            border-radius: 5px;
            border-left: 5px solid blue;
        }
        .user-message {
            background: lightgray;
            color: black;
            padding: 10px;
            margin-bottom: 5px;
            border-radius: 5px;
            border-left: 5px solid green;
        }
        .flight-item {
            background: white;
            color: black;
            padding: 10px;
            margin-bottom: 5px;
            border-radius: 5px;
            border-left: 5px solid red;
        }
    </style>
    <title>Chat Interface</title>
</head>
<body>
    <img src="./static/thy4.png" alt="Logo">
    <button id="startBtn">Start Voice Detection</button>
    <ul id='messages'></ul>
    <ul id='flights'></ul>
    <script>
        let audioContext;
        let mediaStream;
        let mediaRecorder;
        let audioChunks = [];
        let analyser;
        let dataArray;
        let silenceThreshold = -20; // Ses seviyesi eşik değeri (dB)
        let silenceDuration = 3000; // Sessizlik süresi (ms)
        let silenceCounter = 0;
        let silenceLimit = silenceDuration / 30;

        document.getElementById('startBtn').addEventListener('click', async () => {
            try {
                mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                const source = audioContext.createMediaStreamSource(mediaStream);
                analyser = audioContext.createAnalyser();
                source.connect(analyser);
                analyser.fftSize = 2048;
                const bufferLength = analyser.fftSize;
                dataArray = new Float32Array(bufferLength);

                detectSound();

                mediaRecorder = new MediaRecorder(mediaStream);
                mediaRecorder.ondataavailable = event => {
                    audioChunks.push(event.data);
                };

                mediaRecorder.onstop = async () => {
                    console.log("Recorder stopped");
                    const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                    audioChunks = []; // Clear audioChunks for next recording
                    const arrayBuffer = await audioBlob.arrayBuffer();
                    const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
                    const resampledBuffer = await resampleAudioBuffer(audioBuffer, 44100);
                    const wavBlob = audioBufferToWavBlob(resampledBuffer);
                    sendAudioToServer(wavBlob);
                };

            } catch (error) {
                console.error('Error accessing microphone:', error);
            }
        });

        function detectSound() {
            analyser.getFloatTimeDomainData(dataArray);

            let sum = 0.0;
            for (let i = 0; i < dataArray.length; i++) {
                sum += dataArray[i] * dataArray[i];
            }
            let rms = Math.sqrt(sum / dataArray.length);
            let dB = 20 * Math.log10(rms);

            if (dB > silenceThreshold) {
                if (!mediaRecorder || mediaRecorder.state === "inactive") {
                    audioChunks = []; // Clear audioChunks for new recording
                    mediaRecorder.start();
                    console.log("Recording started");
                }
                silenceCounter = 0;
            } else {
                if (mediaRecorder && mediaRecorder.state === "recording") {
                    silenceCounter++;
                    if (silenceCounter > silenceLimit) {
                        mediaRecorder.stop();
                        console.log("Recording stopped");
                        silenceCounter = 0;
                    }
                }
            }

            requestAnimationFrame(detectSound);
        }

        function resampleAudioBuffer(audioBuffer, targetSampleRate) {
            const offlineContext = new OfflineAudioContext(
                audioBuffer.numberOfChannels,
                audioBuffer.duration * targetSampleRate,
                targetSampleRate
            );

            const bufferSource = offlineContext.createBufferSource();
            bufferSource.buffer = audioBuffer;
            bufferSource.connect(offlineContext.destination);
            bufferSource.start(0);

            return offlineContext.startRendering();
        }

        function audioBufferToWavBlob(audioBuffer) {
            const numberOfChannels = audioBuffer.numberOfChannels;
            const length = audioBuffer.length * numberOfChannels * 2 + 44;
            const buffer = new ArrayBuffer(length);
            const view = new DataView(buffer);

            function writeString(view, offset, string) {
                for (let i = 0; i < string.length; i++) {
                    view.setUint8(offset + i, string.charCodeAt(i));
                }
            }

            let offset = 0;

            // RIFF identifier
            writeString(view, offset, 'RIFF'); offset += 4;
            // RIFF chunk length
            view.setUint32(offset, 36 + audioBuffer.length * numberOfChannels * 2, true); offset += 4;
            // RIFF type
            writeString(view, offset, 'WAVE'); offset += 4;
            // format chunk identifier
            writeString(view, offset, 'fmt '); offset += 4;
            // format chunk length
            view.setUint32(offset, 16, true); offset += 4;
            // sample format (raw)
            view.setUint16(offset, 1, true); offset += 2;
            // channel count
            view.setUint16(offset, numberOfChannels, true); offset += 2;
            // sample rate
            view.setUint32(offset, audioBuffer.sampleRate, true); offset += 4;
            // byte rate (sample rate * block align)
            view.setUint32(offset, audioBuffer.sampleRate * numberOfChannels * 2, true); offset += 4;
            // block align (channel count * bytes per sample)
            view.setUint16(offset, numberOfChannels * 2, true); offset += 2;
            // bits per sample
            view.setUint16(offset, 16, true); offset += 2;
            // data chunk identifier
            writeString(view, offset, 'data'); offset += 4;
            // data chunk length
            view.setUint32(offset, audioBuffer.length * numberOfChannels * 2, true); offset += 4;

            // write the PCM samples
            for (let i = 0; i < audioBuffer.numberOfChannels; i++) {
                const channelData = audioBuffer.getChannelData(i);
                for (let j = 0; j < channelData.length; j++) {
                    const sample = Math.max(-1, Math.min(1, channelData[j]));
                    view.setInt16(offset, sample < 0 ? sample * 0x8000 : sample * 0x7FFF, true);
                    offset += 2;
                }
            }

            return new Blob([view], { type: 'audio/wav' });
        }

        function sendAudioToServer(audioBlob) {
            const formData = new FormData();
            formData.append('file', audioBlob, 'recording.wav');
            console.log("Sending audio to server");

            fetch('/s2t', {
                method: 'POST',
                body: formData
            })
            .then(response => response.json())
            .then(data => {
                console.log("Server response:", data);
                var transcript = data.transcript;
                addMessage('user-message', transcript);
                return processOpenAI(transcript);
            })
            .then(responseData => {
                console.log("OpenAI Response:", responseData);
                displayFlights(responseData.flights);  // Use flight data from the response
                return processT2S(responseData.response);  // Send the response text to T2S
            })
            .then(() => {
                console.log("T2S complete");
            })
            .catch(error => console.error('Error:', error));
        }

        function addMessage(className, text) {
            var messages = document.getElementById('messages');
            var message = document.createElement('li');
            message.className = className;
            var content = document.createTextNode(text);
            message.appendChild(content);
            messages.appendChild(message);
        }

        function displayFlights(flights) {
            var flightList = document.getElementById('flights');
            flightList.innerHTML = '';  // Listeyi temizle

            flights.forEach(flight => {
                var listItem = document.createElement('li');
                listItem.className = 'flight-item';
                listItem.innerHTML = `
                    <h2>Flight Number: ${flight.flight_number}</h2>
                    <p><strong>Departure Airport:</strong> ${flight.departure_airport}</p>
                    <p><strong>Arrival Airport:</strong> ${flight.arrival_airport}</p>
                    <p><strong>Departure Time:</strong> ${flight.dep_date_time_hour}</p>
                `;
                flightList.appendChild(listItem);
            });
        }

        function processOpenAI(text) {
            return fetch('/openai', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/x-www-form-urlencoded',
                },
                body: new URLSearchParams({
                    'all_text': text,
                })
            })
            .then(response => response.json())
            .then(data => {
                var responseText = data.response;
                var flights = data.flights; // Uçuş bilgilerini al
                addMessage('openai-message', responseText);
                displayFlights(flights);  // Uçuş bilgilerini görüntüle
                return { response: responseText, flights: flights }; // Yanıt metnini ve uçuş bilgilerini döndür
            })
            .catch(error => console.error('Error:', error));
        }

        function processT2S(text) {
            return fetch('/t2s', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/x-www-form-urlencoded',
                },
                body: new URLSearchParams({
                    'text': text,
                })
            })
            .then(response => {
                if (response.ok) {
                    return response.blob();
                } else {
                    return response.json().then(data => {
                        throw new Error(data.error);
                    });
                }
            })
            .then(blob => {
                var url = URL.createObjectURL(blob);
                var audio = new Audio(url);
                audio.play();
            })
            .catch(error => console.error('Error:', error));
        }
    </script>
</body>
</html>
